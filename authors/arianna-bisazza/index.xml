<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Arianna Bisazza | Gabriele Sarti</title>
    <link>https://gsarti.com/authors/arianna-bisazza/</link>
      <atom:link href="https://gsarti.com/authors/arianna-bisazza/index.xml" rel="self" type="application/rss+xml" />
    <description>Arianna Bisazza</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Gabriele Sarti 2024</copyright><lastBuildDate>Sat, 15 Jun 2024 00:00:00 +0200</lastBuildDate>
    <image>
      <url>https://gsarti.com/img/avatar.jpg</url>
      <title>Arianna Bisazza</title>
      <link>https://gsarti.com/authors/arianna-bisazza/</link>
    </image>
    
    <item>
      <title>Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation</title>
      <link>https://gsarti.com/publication/mirage/</link>
      <pubDate>Sat, 15 Jun 2024 00:00:00 +0200</pubDate>
      <guid>https://gsarti.com/publication/mirage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Primer on the Inner Workings of Transformer-based Language Models</title>
      <link>https://gsarti.com/publication/transformer-lm-inner-workings/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0200</pubDate>
      <guid>https://gsarti.com/publication/transformer-lm-inner-workings/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explaining Language Models with Inseq</title>
      <link>https://gsarti.com/talk/indeep-masterclass-nov23/</link>
      <pubDate>Thu, 02 Nov 2023 10:30:00 +0200</pubDate>
      <guid>https://gsarti.com/talk/indeep-masterclass-nov23/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quantifying the Plausibility of Context Reliance in Neural Machine Translation</title>
      <link>https://gsarti.com/publication/pecore/</link>
      <pubDate>Mon, 02 Oct 2023 00:00:00 +0200</pubDate>
      <guid>https://gsarti.com/publication/pecore/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Are Character-level Translations Worth the Wait? Comparing ByT5 and mT5 for Machine Translation</title>
      <link>https://gsarti.com/publication/char-mt-analysis/</link>
      <pubDate>Tue, 28 Feb 2023 09:47:38 +0200</pubDate>
      <guid>https://gsarti.com/publication/char-mt-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inseq: An Interpretability Toolkit for Sequence Generation Models</title>
      <link>https://gsarti.com/publication/inseq/</link>
      <pubDate>Mon, 27 Feb 2023 09:47:38 +0200</pubDate>
      <guid>https://gsarti.com/publication/inseq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PECoRe: Plausibility Evaluation of Context Usage in Language Models</title>
      <link>https://gsarti.com/project/pecore/</link>
      <pubDate>Tue, 13 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://gsarti.com/project/pecore/</guid>
      <description>&lt;p&gt;PECoRe is a framework using the internal properties of generative language models to identify and attribute context usage in their generations. In particular, the framework is composed by two steps: Context-sensitive Token Identification (CTI), where generated tokens are classified as context-sensitive by contrastively comparing their probabilities with and without context, and Contextual Cues Imputation (CCI), where the dependence of token selected in the CTI step is highlighted by using contrastive attribution. The framework is integrated in the &lt;a href=&#34;https://github.com/inseq-team/inseq&#34;&gt;Inseq interpretability library&lt;/a&gt; and can be easily used thanks to the &lt;code&gt;inseq attribute-context&lt;/code&gt; command. The framework is described in detail in the paper &lt;a href=&#34;https://openreview.net/forum?id=XTHfNGI3zT&#34;&gt;Quantifying the Plausibility of Context Reliance in Neural Machine Translation&lt;/a&gt;, published at ICLR 2024.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DivEMT: Neural Machine Translation Post-Editing Effort Across Typologically Diverse Languages</title>
      <link>https://gsarti.com/publication/divemt/</link>
      <pubDate>Tue, 24 May 2022 01:00:00 +0200</pubDate>
      <guid>https://gsarti.com/publication/divemt/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
