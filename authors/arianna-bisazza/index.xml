<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Arianna Bisazza | Gabriele Sarti</title>
    <link>http://localhost:1313/authors/arianna-bisazza/</link>
      <atom:link href="http://localhost:1313/authors/arianna-bisazza/index.xml" rel="self" type="application/rss+xml" />
    <description>Arianna Bisazza</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Gabriele Sarti 2025</copyright><lastBuildDate>Fri, 23 May 2025 00:00:00 +0200</lastBuildDate>
    <image>
      <url>http://localhost:1313/img/avatar.jpg</url>
      <title>Arianna Bisazza</title>
      <link>http://localhost:1313/authors/arianna-bisazza/</link>
    </image>
    
    <item>
      <title>Steering Large Language Models for Machine Translation Personalization</title>
      <link>http://localhost:1313/publication/steering-litmt/</link>
      <pubDate>Fri, 23 May 2025 00:00:00 +0200</pubDate>
      <guid>http://localhost:1313/publication/steering-litmt/</guid>
      <description></description>
    </item>
    
    <item>
      <title>QE4PE: Word-level Quality Estimation for Human Post-Editing</title>
      <link>http://localhost:1313/publication/qe4pe/</link>
      <pubDate>Thu, 06 Mar 2025 01:00:00 +0200</pubDate>
      <guid>http://localhost:1313/publication/qe4pe/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses</title>
      <link>http://localhost:1313/publication/verbalized-rebus/</link>
      <pubDate>Fri, 02 Aug 2024 01:00:00 +0200</pubDate>
      <guid>http://localhost:1313/publication/verbalized-rebus/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation</title>
      <link>http://localhost:1313/publication/mirage/</link>
      <pubDate>Sat, 15 Jun 2024 00:00:00 +0200</pubDate>
      <guid>http://localhost:1313/publication/mirage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Primer on the Inner Workings of Transformer-based Language Models</title>
      <link>http://localhost:1313/publication/transformer-lm-inner-workings/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0200</pubDate>
      <guid>http://localhost:1313/publication/transformer-lm-inner-workings/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explaining Language Models with Inseq</title>
      <link>http://localhost:1313/talk/indeep-masterclass-nov23/</link>
      <pubDate>Thu, 02 Nov 2023 10:30:00 +0200</pubDate>
      <guid>http://localhost:1313/talk/indeep-masterclass-nov23/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quantifying the Plausibility of Context Reliance in Neural Machine Translation</title>
      <link>http://localhost:1313/publication/pecore/</link>
      <pubDate>Mon, 02 Oct 2023 00:00:00 +0200</pubDate>
      <guid>http://localhost:1313/publication/pecore/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Are Character-level Translations Worth the Wait? Comparing ByT5 and mT5 for Machine Translation</title>
      <link>http://localhost:1313/publication/char-mt-analysis/</link>
      <pubDate>Tue, 28 Feb 2023 09:47:38 +0200</pubDate>
      <guid>http://localhost:1313/publication/char-mt-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inseq: An Interpretability Toolkit for Sequence Generation Models</title>
      <link>http://localhost:1313/publication/inseq/</link>
      <pubDate>Mon, 27 Feb 2023 09:47:38 +0200</pubDate>
      <guid>http://localhost:1313/publication/inseq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Attributing Context Usage in Language Models</title>
      <link>http://localhost:1313/project/pecore/</link>
      <pubDate>Tue, 13 Dec 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/pecore/</guid>
      <description>&lt;p&gt;PECoRe is a framework using the internal properties of generative language models to identify and attribute context usage in their generations. In particular, the framework is composed by two steps: Context-sensitive Token Identification (CTI), where generated tokens are classified as context-sensitive by contrastively comparing their probabilities with and without context, and Contextual Cues Imputation (CCI), where the dependence of token selected in the CTI step is highlighted by using contrastive attribution. The framework is integrated in the &lt;a href=&#34;https://github.com/inseq-team/inseq&#34;&gt;Inseq interpretability library&lt;/a&gt; and can be easily used thanks to the &lt;code&gt;inseq attribute-context&lt;/code&gt; command. The framework is described in detail in the paper &lt;a href=&#34;http://localhost:1313/publication/pecore/&#34;&gt;Quantifying the Plausibility of Context Reliance in Neural Machine Translation&lt;/a&gt;, published at ICLR 2024, and its extension MIRAGE was created to support answer attribution in RAG applications &lt;a href=&#34;http://localhost:1313/publication/mirage/&#34;&gt;Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DivEMT: Neural Machine Translation Post-Editing Effort Across Typologically Diverse Languages</title>
      <link>http://localhost:1313/publication/divemt/</link>
      <pubDate>Tue, 24 May 2022 01:00:00 +0200</pubDate>
      <guid>http://localhost:1313/publication/divemt/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
