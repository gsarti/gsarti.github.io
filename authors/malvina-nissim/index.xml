<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Malvina Nissim | Gabriele Sarti</title>
    <link>https://gsarti.com/authors/malvina-nissim/</link>
      <atom:link href="https://gsarti.com/authors/malvina-nissim/index.xml" rel="self" type="application/rss+xml" />
    <description>Malvina Nissim</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Gabriele Sarti 2025</copyright><lastBuildDate>Thu, 06 Mar 2025 01:00:00 +0200</lastBuildDate>
    <image>
      <url>https://gsarti.com/img/avatar.jpg</url>
      <title>Malvina Nissim</title>
      <link>https://gsarti.com/authors/malvina-nissim/</link>
    </image>
    
    <item>
      <title>QE4PE: Word-level Quality Estimation for Human Post-Editing</title>
      <link>https://gsarti.com/publication/qe4pe/</link>
      <pubDate>Thu, 06 Mar 2025 01:00:00 +0200</pubDate>
      <guid>https://gsarti.com/publication/qe4pe/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses</title>
      <link>https://gsarti.com/publication/verbalized-rebus/</link>
      <pubDate>Fri, 02 Aug 2024 01:00:00 +0200</pubDate>
      <guid>https://gsarti.com/publication/verbalized-rebus/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi-property Steering of Large Language Models with Dynamic Activation Composition</title>
      <link>https://gsarti.com/publication/dynamic-activation-composition/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0200</pubDate>
      <guid>https://gsarti.com/publication/dynamic-activation-composition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>IT5: Text-to-text Pretraining for Italian Language Understanding and Generation</title>
      <link>https://gsarti.com/publication/it5/</link>
      <pubDate>Mon, 20 May 2024 01:00:00 +0200</pubDate>
      <guid>https://gsarti.com/publication/it5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quantifying the Plausibility of Context Reliance in Neural Machine Translation</title>
      <link>https://gsarti.com/publication/pecore/</link>
      <pubDate>Mon, 02 Oct 2023 00:00:00 +0200</pubDate>
      <guid>https://gsarti.com/publication/pecore/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inseq: An Interpretability Toolkit for Sequence Generation Models</title>
      <link>https://gsarti.com/publication/inseq/</link>
      <pubDate>Mon, 27 Feb 2023 09:47:38 +0200</pubDate>
      <guid>https://gsarti.com/publication/inseq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Attributing Context Usage in Language Models</title>
      <link>https://gsarti.com/project/pecore/</link>
      <pubDate>Tue, 13 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://gsarti.com/project/pecore/</guid>
      <description>&lt;p&gt;PECoRe is a framework using the internal properties of generative language models to identify and attribute context usage in their generations. In particular, the framework is composed by two steps: Context-sensitive Token Identification (CTI), where generated tokens are classified as context-sensitive by contrastively comparing their probabilities with and without context, and Contextual Cues Imputation (CCI), where the dependence of token selected in the CTI step is highlighted by using contrastive attribution. The framework is integrated in the &lt;a href=&#34;https://github.com/inseq-team/inseq&#34;&gt;Inseq interpretability library&lt;/a&gt; and can be easily used thanks to the &lt;code&gt;inseq attribute-context&lt;/code&gt; command. The framework is described in detail in the paper &lt;a href=&#34;https://gsarti.com/publication/pecore/&#34;&gt;Quantifying the Plausibility of Context Reliance in Neural Machine Translation&lt;/a&gt;, published at ICLR 2024, and its extension MIRAGE was created to support answer attribution in RAG applications &lt;a href=&#34;https://gsarti.com/publication/mirage/&#34;&gt;Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Teaching NLP with Bracelets and Restaurant Menus: An Interactive Workshop for Italian Students</title>
      <link>https://gsarti.com/publication/teaching-nlp-bracelets-menus/</link>
      <pubDate>Sun, 06 Jun 2021 09:47:38 +0200</pubDate>
      <guid>https://gsarti.com/publication/teaching-nlp-bracelets-menus/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
