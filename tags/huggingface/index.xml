<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HuggingFace | Gabriele Sarti</title>
    <link>https://gsarti.com/tags/huggingface/</link>
      <atom:link href="https://gsarti.com/tags/huggingface/index.xml" rel="self" type="application/rss+xml" />
    <description>HuggingFace</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Gabriele Sarti 2024</copyright><lastBuildDate>Mon, 20 May 2024 01:00:00 +0200</lastBuildDate>
    <image>
      <url>https://gsarti.com/img/avatar.jpg</url>
      <title>HuggingFace</title>
      <link>https://gsarti.com/tags/huggingface/</link>
    </image>
    
    <item>
      <title>IT5: Text-to-text Pretraining for Italian Language Understanding and Generation</title>
      <link>https://gsarti.com/publication/it5/</link>
      <pubDate>Mon, 20 May 2024 01:00:00 +0200</pubDate>
      <guid>https://gsarti.com/publication/it5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inseq: An Interpretability Toolkit for Sequence Generation Models</title>
      <link>https://gsarti.com/publication/inseq/</link>
      <pubDate>Mon, 27 Feb 2023 09:47:38 +0200</pubDate>
      <guid>https://gsarti.com/publication/inseq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inseq: An Interpretability Toolkit for Sequence Generation Models</title>
      <link>https://gsarti.com/project/inseq/</link>
      <pubDate>Tue, 13 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://gsarti.com/project/inseq/</guid>
      <description>&lt;p&gt;Inseq is a Pytorch-based hackable toolkit to democratize the study of interpretability for sequence generation models. Inseq supports a wide set of models from the ðŸ¤— Transformers library and an ever-growing set of feature attribution methods, leveraging in part the widely-used Captum library. For a quick introduction to common use cases, see the &lt;a href=&#34;https://inseq.readthedocs.io/examples/quickstart.html&#34;&gt;Getting started with Inseq&lt;/a&gt; page.&lt;/p&gt;
&lt;p&gt;Using Inseq, feature attribution maps that can be saved, reloaded, aggregated and visualized either as HTMLs (with Jupyter notebook support) or directly in the console using rich. Besides simple attribution, Inseq also supports features like step score extraction, attribution aggregation and attributed functions customization for more advanced use cases.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contrastive Language-Image Pre-training for the Italian Language</title>
      <link>https://gsarti.com/publication/clip-italian/</link>
      <pubDate>Thu, 19 Aug 2021 09:47:38 +0200</pubDate>
      <guid>https://gsarti.com/publication/clip-italian/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contrastive Image-Text Pretraining for Italian</title>
      <link>https://gsarti.com/project/clip-italian/</link>
      <pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://gsarti.com/project/clip-italian/</guid>
      <description>&lt;p&gt;CLIP is a multimodel model that can learn to represent images and text jointly in the same space. In this project, we aim to propose the first CLIP model trained on Italian data, that in this context can be considered a low resource language. Using a few techniques, we have been able to fine-tune a SOTA Italian CLIP model with only 1.4 million training samples.&lt;/p&gt;
&lt;p&gt;For more information, refer to our &lt;a href=&#34;https://huggingface.co/spaces/clip-italian/clip-italian-demo&#34;&gt;demo&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
